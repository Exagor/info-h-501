{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image derivative\n",
    "\n",
    "Image derivative can be approximated by discrete differentiation operators\n",
    "\n",
    "\\begin{equation}\n",
    "f'(x) = \\lim_{h\\to0} \\frac{f(x+h) - f(x)}{h}\n",
    "\\end{equation}\n",
    "\n",
    "for images, the equivallent is given by the convolution ($*$) of the image $\\mathbf{A}$  by the Prewitt operator,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{G_x} = \\begin{bmatrix} \n",
    "+1 & 0 & -1 \\\\\n",
    "+1 & 0 & -1 \\\\\n",
    "+1 & 0 & -1\n",
    "\\end{bmatrix} * \\mathbf{A}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mbox{and} \\quad \\quad \\mathbf{G_y} = \\begin{bmatrix} \n",
    "+1 & +1 & +1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "-1 & -1 & -1\n",
    "\\end{bmatrix} * \\mathbf{A}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harris corner detection\n",
    "\n",
    "see https://docs.opencv.org\n",
    "Let's look for corners. Since corners represents a variation in the gradient in the image, we will look for this \"variation\".\n",
    "\n",
    "Consider a grayscale image I. We are going to sweep a window $w(x,y)$ (with displacements u in the x direction and v in the y direction) I and will calculate the variation of intensity.\n",
    "\n",
    "\\begin{equation} \n",
    "E(u,v) = \\sum _{x,y} w(x,y)[ I(x+u,y+v) - I(x,y)]^{2}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "$w(x,y)$ is the window at position $(x,y)$\n",
    "\n",
    "$I(x,y)$ is the intensity at $(x,y)$\n",
    "\n",
    "$I(x+u,y+v)$ is the intensity at the moved window $(x+u,y+v)$\n",
    "    \n",
    "Since we are looking for windows with corners, we are looking for windows with a large variation in intensity. Hence, we have to maximize the equation above, specifically the term:\n",
    "\n",
    "$\\sum _{x,y}[ I(x+u,y+v) - I(x,y)]^{2}$\n",
    "\n",
    "Using Taylor expansion:\n",
    "\\begin{equation} \n",
    "E(u,v) \\approx \\sum _{x,y}[ I(x,y) + u I_{x} + vI_{y} - I(x,y)]^{2}\n",
    "\\end{equation} \n",
    "\n",
    "Expanding the equation and cancelling properly:\n",
    "\n",
    "\\begin{equation} \n",
    "E(u,v) \\approx \\sum _{x,y} u^{2}I_{x}^{2} + 2uvI_{x}I_{y} + v^{2}I_{y}^{2}\n",
    "\\end{equation} \n",
    "\n",
    "Which can be expressed in a matrix form as:\n",
    "\n",
    "\\begin{equation}\n",
    "E(u,v) \\approx \\begin{bmatrix} u & v \\end{bmatrix} \\left ( \\displaystyle \\sum_{x,y} w(x,y) \\begin{bmatrix} I_x^{2} & I_{x}I_{y} \\\\ I_xI_{y} & I_{y}^{2} \\end{bmatrix} \\right ) \\begin{bmatrix} u \\\\ v \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Let's denote:\n",
    "\\begin{equation}\n",
    "M = \\displaystyle \\sum_{x,y} w(x,y) \\begin{bmatrix} I_x^{2} & I_{x}I_{y} \\\\ I_xI_{y} & I_{y}^{2} \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "So, our equation now is:\n",
    "\n",
    "\\begin{equation}\n",
    "E(u,v) \\approx \\begin{bmatrix} u & v \\end{bmatrix} M \\begin{bmatrix} u \\\\ v \\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "A score is calculated for each window, to determine if it can possibly contain a corner:\n",
    "\n",
    "\\begin{equation}\n",
    "R = det(M) - k(trace(M))^{2}\n",
    "\\label{eq:vector_ray}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "$det(M) = \\lambda_{1}\\lambda_{2}$\n",
    "\n",
    "$trace(M) = \\lambda_{1}+\\lambda_{2}$\n",
    "\n",
    "Harris suggested to use $\\eqref{eq:vector_ray}$ to speed up the corner detection instead of explicitely compute $\\lambda_{1,2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "g = data.camera()\n",
    "\n",
    "# Detector parameters\n",
    "thresh = 1\n",
    "blockSize = 2\n",
    "apertureSize = 3\n",
    "k = 0.04\n",
    "\n",
    "# Detecting corners\n",
    "dst = cv2.cornerHarris(g, blockSize, apertureSize, k)\n",
    "\n",
    "# Normalizing\n",
    "#dst_norm = np.empty(dst.shape, dtype=np.float32)\n",
    "#cv.normalize(dst, dst_norm, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
    "#dst_norm_scaled = cv.convertScaleAbs(dst_norm)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage.feature import corner_harris, corner_subpix, corner_peaks\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.draw import ellipse\n",
    "\n",
    "# Sheared checkerboard\n",
    "tform = AffineTransform(scale=(1.3, 1.1), rotation=1, shear=0.7,\n",
    "                        translation=(110, 30))\n",
    "image = warp(data.checkerboard()[:90, :90], tform.inverse,\n",
    "             output_shape=(200, 310))\n",
    "# Ellipse\n",
    "rr, cc = ellipse(160, 175, 10, 100)\n",
    "image[rr, cc] = 1\n",
    "# Two squares\n",
    "image[30:80, 200:250] = 1\n",
    "image[80:130, 250:300] = 1\n",
    "\n",
    "coords = corner_peaks(corner_harris(image), min_distance=5, threshold_rel=0.02)\n",
    "coords_subpix = corner_subpix(image, coords, window_size=13)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[10,10])\n",
    "ax.imshow(image, cmap=plt.cm.gray)\n",
    "ax.plot(coords[:, 1], coords[:, 0], color='cyan', marker='o',\n",
    "        linestyle='None', markersize=6)\n",
    "ax.plot(coords_subpix[:, 1], coords_subpix[:, 0], '+r', markersize=15)\n",
    "ax.axis((0, 310, 200, 0))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage.util import img_as_float\n",
    "from skimage.feature import (corner_harris, corner_subpix, corner_peaks,\n",
    "                             plot_matches)\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import ransac\n",
    "\n",
    "\n",
    "# generate synthetic checkerboard image and add gradient for the later matching\n",
    "checkerboard = img_as_float(data.checkerboard())\n",
    "img_orig = np.zeros(list(checkerboard.shape) + [3])\n",
    "img_orig[..., 0] = checkerboard\n",
    "gradient_r, gradient_c = (np.mgrid[0:img_orig.shape[0],\n",
    "                                   0:img_orig.shape[1]]\n",
    "                          / float(img_orig.shape[0]))\n",
    "img_orig[..., 1] = gradient_r\n",
    "img_orig[..., 2] = gradient_c\n",
    "img_orig = rescale_intensity(img_orig)\n",
    "img_orig_gray = rgb2gray(img_orig)\n",
    "\n",
    "# warp synthetic image\n",
    "tform = AffineTransform(scale=(0.9, 0.9), rotation=0.2, translation=(20, -10))\n",
    "img_warped = warp(img_orig, tform.inverse, output_shape=(200, 200))\n",
    "img_warped_gray = rgb2gray(img_warped)\n",
    "\n",
    "# extract corners using Harris' corner measure\n",
    "coords_orig = corner_peaks(corner_harris(img_orig_gray), threshold_rel=0.001,\n",
    "                           min_distance=5)\n",
    "coords_warped = corner_peaks(corner_harris(img_warped_gray),\n",
    "                             threshold_rel=0.001, min_distance=5)\n",
    "\n",
    "# determine sub-pixel corner position\n",
    "coords_orig_subpix = corner_subpix(img_orig_gray, coords_orig, window_size=9)\n",
    "coords_warped_subpix = corner_subpix(img_warped_gray, coords_warped,\n",
    "                                     window_size=9)\n",
    "\n",
    "\n",
    "def gaussian_weights(window_ext, sigma=1):\n",
    "    y, x = np.mgrid[-window_ext:window_ext+1, -window_ext:window_ext+1]\n",
    "    g = np.zeros(y.shape, dtype=np.double)\n",
    "    g[:] = np.exp(-0.5 * (x**2 / sigma**2 + y**2 / sigma**2))\n",
    "    g /= 2 * np.pi * sigma * sigma\n",
    "    return g\n",
    "\n",
    "\n",
    "def match_corner(coord, window_ext=5):\n",
    "    r, c = np.round(coord).astype(np.intp)\n",
    "    window_orig = img_orig[r-window_ext:r+window_ext+1,\n",
    "                           c-window_ext:c+window_ext+1, :]\n",
    "\n",
    "    # weight pixels depending on distance to center pixel\n",
    "    weights = gaussian_weights(window_ext, 3)\n",
    "    weights = np.dstack((weights, weights, weights))\n",
    "\n",
    "    # compute sum of squared differences to all corners in warped image\n",
    "    SSDs = []\n",
    "    for cr, cc in coords_warped:\n",
    "        window_warped = img_warped[cr-window_ext:cr+window_ext+1,\n",
    "                                   cc-window_ext:cc+window_ext+1, :]\n",
    "        SSD = np.sum(weights * (window_orig - window_warped)**2)\n",
    "        SSDs.append(SSD)\n",
    "\n",
    "    # use corner with minimum SSD as correspondence\n",
    "    min_idx = np.argmin(SSDs)\n",
    "    return coords_warped_subpix[min_idx]\n",
    "\n",
    "\n",
    "# find correspondences using simple weighted sum of squared differences\n",
    "src = []\n",
    "dst = []\n",
    "for coord in coords_orig_subpix:\n",
    "    src.append(coord)\n",
    "    dst.append(match_corner(coord))\n",
    "src = np.array(src)\n",
    "dst = np.array(dst)\n",
    "\n",
    "\n",
    "# estimate affine transform model using all coordinates\n",
    "model = AffineTransform()\n",
    "model.estimate(src, dst)\n",
    "\n",
    "# robustly estimate affine transform model with RANSAC\n",
    "model_robust, inliers = ransac((src, dst), AffineTransform, min_samples=3,\n",
    "                               residual_threshold=2, max_trials=100)\n",
    "outliers = inliers == False\n",
    "\n",
    "\n",
    "# compare \"true\" and estimated transform parameters\n",
    "print(\"Ground truth:\")\n",
    "print(f'Scale: ({tform.scale[1]:.4f}, {tform.scale[0]:.4f}), '\n",
    "      f'Translation: ({tform.translation[1]:.4f}, '\n",
    "      f'{tform.translation[0]:.4f}), '\n",
    "      f'Rotation: {-tform.rotation:.4f}')\n",
    "print(\"Affine transform:\")\n",
    "print(f'Scale: ({model.scale[0]:.4f}, {model.scale[1]:.4f}), '\n",
    "      f'Translation: ({model.translation[0]:.4f}, '\n",
    "      f'{model.translation[1]:.4f}), '\n",
    "      f'Rotation: {model.rotation:.4f}')\n",
    "print(\"RANSAC:\")\n",
    "print(f'Scale: ({model_robust.scale[0]:.4f}, {model_robust.scale[1]:.4f}), '\n",
    "      f'Translation: ({model_robust.translation[0]:.4f}, '\n",
    "      f'{model_robust.translation[1]:.4f}), '\n",
    "      f'Rotation: {model_robust.rotation:.4f}')\n",
    "\n",
    "# visualize correspondence\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1,figsize=[10,10])\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "inlier_idxs = np.nonzero(inliers)[0]\n",
    "plot_matches(ax[0], img_orig_gray, img_warped_gray, src, dst,\n",
    "             np.column_stack((inlier_idxs, inlier_idxs)), matches_color='b')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Correct correspondences')\n",
    "\n",
    "outlier_idxs = np.nonzero(outliers)[0]\n",
    "plot_matches(ax[1], img_orig_gray, img_warped_gray, src, dst,\n",
    "             np.column_stack((outlier_idxs, outlier_idxs)), matches_color='r')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Faulty correspondences')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integral images\n",
    "\n",
    "In order to speed up computation some approximation can be done. One very intersting algorithm is the integral image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ima = np.zeros((50,50),dtype=np.uint8)\n",
    "ima[20:30,20:30] = 1\n",
    "ima[40:45,10:15] = 1\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(ima)\n",
    "integral_image = cv2.integral(ima)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(integral_image)\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Grab some test data.\n",
    "Z = integral_image\n",
    "m,n = Z.shape\n",
    "X, Y = np.mgrid[0:m,0:n]\n",
    "\n",
    "# Plot a basic wireframe.\n",
    "ax.plot_wireframe(X, Y, Z, rstride=1, cstride=1)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "class quad():\n",
    "    def __init__(self,xy,w,h):\n",
    "        self.xy = xy\n",
    "        self.w = w \n",
    "        self.h = h\n",
    "        self.pos_a = (xy[1], xy[0])\n",
    "        self.pos_b = (xy[1] + w, xy[0])\n",
    "        self.pos_c = (xy[1] + w, xy[0] + h)\n",
    "        self.pos_d = (xy[1], xy[0] + h)\n",
    "\n",
    "    def sample(self,image):\n",
    "        a = image[self.pos_a]\n",
    "        b = image[self.pos_b]\n",
    "        c = image[self.pos_c]\n",
    "        d = image[self.pos_d]\n",
    "        return a+c-d-b,(a,b,c,d)\n",
    "    \n",
    "    def plot(self,ax):\n",
    "        rect = Rectangle(self.xy,self.w,self.h,facecolor=\"r\", alpha=0.8)\n",
    "        ax.add_patch(rect)\n",
    "        for s,p in zip(['a','b','c','d'],[self.pos_a,self.pos_b,self.pos_c,self.pos_d]):\n",
    "            ax.text(p[0],p[1],s,c='y')\n",
    "        \n",
    "q = quad((15,15),10,10)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.imshow(ima)\n",
    "q.plot(ax)\n",
    "s,abcd = q.sample(integral_image)\n",
    "print(f'integral = {s}, abcd = {abcd}')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data.astronaut()\n",
    "sift = cv2.SIFT_create()\n",
    "kp = sift.detect(g,None)\n",
    "img=cv2.drawKeypoints(g,kp,g,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imsave('astro_points.png',img)\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
